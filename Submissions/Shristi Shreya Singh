# Outreachy Project - HOT Tech: Feedback and Technical Support
## Project Title

To better understand the product, users and stakeholders in an effort to understand how satisfied they are with the current feedback mechanisms and how it can be improved.


### Inspiration

Over the course of the last one week, I tried my best to learn about the feedback system in the HOT internal community in context, and to better understand the community member’s experiences about it at both global and the regional level staff (particularly Jakarta and Nigeria office). I also had the privilege to talk to a few voting members of the community. The reason for collecting views from both the offices is to understand the difference in nature of feedback collection and working for a remote staff working on global scale and a regional staff based in an office. Though there is an office situated in Washington DC for the global staff, but it hardly has only 1 or 2 staff there. I chose interviewing internal HOT community members among the various options given between was completely my personal choice and as I  always get so delighted that there are people out there making high quality information available for anyone to use it for free. It's because of organizations like these that the world keeps moving, and gives a hope for the future generations. I just love what people are doing for OSM.I think that there is a huge potential and I have also used it extensively in past as I was associated with mapping for past two years now. I wanted to learn a bit more about how the internal community works for this awesome organisation. 

Interviews focused on how frequently various types of feedback are collected at the different scales(regional and global), the general topics on which the feedbacks are collected, way of feedback collection, are they heard/addressed to, an approximate action period, rating for the system in general and the changes that they would love to see. 

I have divided the report into two parts one focused on technical feedback(which includes feedback regarding the current status of HOT projects, coordination possibilities, priorities for tool development, and for hosting and operations aspects of HOT tools) and the other section on feedback regarding non-technical aspects such as working conditions, benefits etc. Though my major focus has been the technical feedback aspect . I consider that feedback regarding non-technical aspects is equally important as it influences a correct mental state and a well being of the HOT internal community members and their willingness to work and co-ordinate thereby influencing development of any project or tool and their active participation in providing it’s feedback. Only a correct and happy mental state can give a positive criticism. 

I found that the global staff seems to be more satisfied with the system(In order to easily understand this system. I have mapped out the entire process using google drawing that provides a brief idea. You can find it [here](https://docs.google.com/drawings/d/1sTQf4fctXdClBw2lQ9PNDWdKOzQShemolYj5FzfkYCI/edit?usp=sharing). This whole process has been explained in detail in the following sections) as in how the technical feedback is collected in the community and how it is dealt with afterwards with an average rating of 8 when compared to the regional staff with an average rating of 7 however the global staff had a wide variety of opinions/issues in their answers and regional staff at both offices mentioned almost similar problems. Alarmingly I noticed that people had a lack of knowledge about the feedback collection system in the community as some of the innovative features mentioned by the staff were completely unknown to the others. 

Overall I wanted to have an insight into the working and I made a brief glance which has been mentioned in the following sections individually focused on each question I asked. I also had the privilege to know about the different sections of the HOT-OSM community and their working such as the communication team, tasking manager, engineering team etc and how the feedback system works for them differently. 

Coming to the initial process of approaching the members, I approached almost 15-20 staff members by going through the HOT community website. Fortunately I got an overwhelming response. And depending upon our time zones and availability during the last few days, I scheduled calls(particularly hangouts) with three members each at global and regional offices(two based in Jakarta and one in Nigeria).The average time for which they have associated with the community is around 2.5 years giving me an assurance that they were well versed with the feedback collection and details related to how it works in the community. Unfortunately I don’t have permission and from the interviewees so I won’t be disclosing any direct statements made by them publicly in this report.

You can find the details of interviews done [here](https://docs.google.com/document/d/1M7hAslI2xRTwTF_xBxbrurdinjx8Z2daWFrHsxDXo0g/edit?usp=sharing).

I also had the privilege to talk to few voting members and know their satisfaction and preference for the feedback system in the community for their valuable inputs which has been mentioned in the last section of this report. 
## Ideation
### Technical Feedback 

**The general topics on which the feedbacks are collected?**


* As expected, the topic of feedback collection varied a lot for different teams and also for the global and the regional staff. The topics range from the current status of HOT projects, coordination possibilities, priorities for tool development, and for hosting and operations aspects of HOT tools.


**How frequently is feedback collected?**

* For HOT global level, I found that feedback is collected only once per year through Staff Performance Review, as well as different meetings on weekly or bi-weekly frequency mostly performed remotely. 
 
* Voting members have only one (general) meeting per year - although can have more(as indicated by few staff members); but can also attend the monthly board of directors meetings. Surveys are done inconsistently to the membership. A detailed section based on the satisfaction and preferences of the voting members has included at last of this report.
 
* For HOT-regional level, it takes monthly by meeting team. For project levels in regional offices, it takes minimum every 2 weeks or less, as needed  to get feedback and evaluation from previous activities. 
 
But on a broader term what I understood is that feedback on tech tools and projects happens quite regularly. And the internal community members are satisfied with it. 
 
 
**Mode of Feedback collection?**


* This was one of the most important questions and a topic that indicated the difference of opinion and lack of information at different levels in the community. What I got is that the mode of feedback collection  really depends on what the feedback is for. 
 
* Each program has a unique or different feedback mechanism, and process in which feedback is collected. Take for example, a tech tool such as The HOT Tasking Manager, the team working on it collects feedback whenever they are testing the tool, or, when the tool is not delivering as expected, the community of users gives feedback there and then on slack(such as hot_irc_channel) and other communication platforms(such as Gitter.im or riot.im(being used by Turkish and Greek community as reported)). This is different from a field mapping program/project. A field mapping project will collect feedback from the community to be mapped, from mappers, and from HOT project partners or donors on the features to be mapped and this feedback enables the project or program team to refine their approach to project implementations. There is no specific feedback tool used, especially for field projects, it's mainly through discussions with the stakeholders. 
 
* Some platforms such as [this](https://status.hotosm.org/) are used by the tech team to communicate the status of tools. However I think that it would  be great probably to use it as a feedback gathering tool as well, as an additional feature. Github or Slack is also used in some cases for collecting feedback. Members indicated that slack proves to be a faster media. Fortunately I was also able to collect some sample feedback forms from the community members such as [this](https://docs.google.com/forms/d/e/1FAIpQLSd4fl6fEwXop428Pm-08W1omm_oiZUzdzQ8G2gYeOJiYEnXOQ/viewform) and [this](https://docs.google.com/forms/d/e/1FAIpQLSfJ40J_dPE35IdhyjCFBUn3UwaPDwkkTCMqnDrxYu2BWP746g/viewform).




Going through the forms I found that these are well designed however I found a blunt repetition of the majority of questions in both forms. 
 
* A global staff member talked about availability of an anonymous form online and a page with some instructions on how to contact the directors. However most of the other staff whom I talked to seemed to be completely unaware of this which is quite alarming in itself and represent a mere lack of information about the system among the majority of employees. 
 
* Regional staff have a completely different mode of feedback collection, they usually report to our country manager --> after that, the country manager will bring that issue to weekly meetings with the Program Director ---> maybe wait until the program director or else take action? That last part is still not clear in my opinion. 

#### Satisfaction

* Regarding Global staff, I found out that they are more informed in general and are quite happy with how the feedback is collected for tools and projects. They mention different platforms such as slack, github, Gitter and riot channels dedicated for discussion and to collect feedback. The response time is also less on these platforms. Google forms and questionnaires are circulated time to time as well.
 
* For Regional staff, they think compared to the earlier years (in 2012-2014) HOT have a lot improvement in terms of feedback system which is very satisfying. Back then in 2012, the staff indicated lack of any such kind of system. If they had a problem, then they had to talk to their supervisor or country manager. For now, they have a kind of system about how the feedback is collected.

#### Preference

* The lack of a proper framework and the number of stages involved in the feedback collection process for regional staff makes it more and more complex as well as delaying the results at the same time. Sometimes when they have feedback, it takes a while to get an answer from higher up and currently if they have some feedback, it is only through an email or regular meeting indicating a lack of any proper channel or framework such as a proper platform that makes the system easy to approach and fasten up the process. 

* However the need for a more centralised and formal platform for collecting feedback was observed. Having to deal with different platforms for different issues is quite confusing and time taking for the community members. When asked about if they would prefer a forum based system(discussed in the recommendation section in detail, they gladly agreed to it and suggested that it would be great if implemented). You can find the response to questions asked [here](https://docs.google.com/spreadsheets/d/1fuQL91Rvsc9CtmjtZBFbXnAwVTZ1bDrw1ozToHQNm9E/edit?usp=sharing). I circulated a [google form](https://docs.google.com/forms/d/e/1FAIpQLSe-oLAfRe_Gz4ji2T0hKZgQ0L5u7sgNdMwiKu-KYj385g5z5Q/viewform?usp=sf_link) with my suggested recommendations in order to seek opinion from the members regarding whether it will be useful or not. 


 
**Are the Feedbacks heard to? If yes, what’s the average action period?**

#### Satisfaction

Both regional and global staff gave an assurance regarding this, let it be sooner or later in some cases or other depending upon the gravity of the situation. 
 
* When there’s something negatively impacting a project it’s usually addressed immediately and in other cases  the response time depends on the difficulty of the issue. 
 
#### Preferences 

* As a global remote team and even for the regional offices, some issues are a bit difficult to solve particularly when they need to find previous action reports and findings before taking an actual action. There is a  lack of accessibility to the previous reports and findings. As of now these issues take roughly around 6 months or even longer to be solved or addressed to. The forum based system mentioned above also takes this into account and all the previous reports and actions remain saved(addressed in detail in the recommendation section). Also as slack is the commonly used channel a slackbot maybe an option too that transfers the report in some other page/location.
 

 
* Lack of information regarding the general action period. It can be improved by actually implementing any media to know the progress of feedback, only if it takes longer time. A ticket-based system has been recommended for it. It was highly appreciated by the members in the google form circulated as well.
 
**On a scale of 1-10 how satisfied you are with the feedback system and it's working?**
 

* Coming to the stats, among the three members that I interviewed working in the global staff gave a rating of 10, 9 and 5 respectively making the average 8. And for regional staff it was 8,8 and 5 respectively making the average 7. 
 
* I observed that the interviewees had a different level of satisfaction with the way technical feedback collection works in the community and the way it is heard to or acted upon. In general, the rating for former was significantly better than the later one with the actual rating of 10, 10, 6, 9, 8 and 6(with an average of 8.17) respectively for global and regional staff while for action it is 10, 8, 4, 7, 8 and 4(with an average of around 6.83) in the same order. 

##### Aggregating collected raw data

I tried to aggregate this raw data in the form of a histogram using Matplotlib which is a plotting library for the Python programming language in order to make the visualisation and analysis quite easy . I have also reported various parameters such as Mean, median, standard deviation, min, max, variance. You can find the histogram and the values [here](https://docs.google.com/document/d/1b8StV7bVANKsT3-NiPvJMMILzAGTVgPOEgHPJq46mzA/edit?usp=sharing).

##### Analysing the aggregated data

X-axis in the graph represents the score and Y-axis represents the frequency. Both the graphs represent a bi-modal distribution with two peaks. The data is not uniform or shows a particular shape though this can account for less number of values collected(i.e 6). 


I used the average of both as a general rating given by staff members as mentioned in the beginning of the section.
 
**Any more suggestions to improve the current scenario?**


I got a number of suggestions for improvement of the current scenario which has been described in the following points.

* There is a need to set up a more formal, and an escalation process and some system which also provides the tracking of progress once the feedback is registered. There can also be a general policy regarding this.
 
* There is a need for a more organised and centralised channel/mode of technical feedback collection. Where storing of previous reports is also possible. The system is distributed in tits and bits which creates a lot of confusion.

### Non-Technical Feedback 

**The general topics on which the feedbacks are collected?**

* Many of the regional staff members suggested the need for an anonymous feedback system for topics other than project progress and tools which can be explained by the remote nature of the global community while regional staff is based in an office which has been ever growing.

**How frequently is feedback collected?**

Feedback on non-technical issues are quite rare maybe once or twice in an year and the members seem to be quite unsatisfied with it. 

They definitely preferred a more regular and a well framed system for giving non-technical feedback.
 
 
**Mode of Feedback collection?**

#### Satisfaction
A lack of satisfaction with the process can be seen. As it generally takes a lot of time, very inconsistent, no proper channel or framework.

#### Preferences
Regarding non-technical feedback collection, a regional staff based at Nigeria office raised a point of lack of privacy during the feedback collection process as if they have some feedback, it is only through an email or regular meeting that happens publically they can't always say all the things they have in mind especially in a front of everyone because it might hurt someone. An one-on-one meeting or even zendesk or a similar system to store their feedback anonymously can be a great option. 
 
**Are the Feedbacks heard to? If yes, what’s the average action period?**

#### Satisfaction
* For non-technical feedback(which I assume to be more of importance for regional offices), it depends upon the extent of the issue if it is something that can be done by the local manager it is addressed to at the earliest. The more level managers need to act, the more time it takes.
 
#### Preference
A more formal and accountable feedback collection system. Where tracking of given feedback is possible.
 
**On a scale of 1-10 how satisfied you are with the feedback system and it's working?**
 

* Unfortunately I didn’t collect a rating for non-technical feedback. But a sense of dis-satisfaction can be clearly seen.
 
**Any more suggestions to improve the current scenario?**


I got a number of suggestions for improvement of the current scenario which has been described in the following points.

 
* The regional offices particularly Jakarta has a need among staff members to hire an HR or to have a similar system or portal as the system can be improved if they have the right person or division  to talk or report to or any tool that can serve the purpose. Also staff members seem to be quite unaware regarding the methodologies followed in feedback collections and tools and portals used. So, these divisions can also help with spreading information.
 
* Many of the regional staff members suggested the need for an anonymous feedback system for topics other than project progress and tools which can be explained by the remote nature of the global community while regional staff is based in an office which has been ever growing.
 
 
### Implementation
#### **Recommendations**


Based on the surveys done and the views I recieved, I have following recommendations for the system:

* ***Forums* based system**
 
A forum based system can be implemented to get feedback. An Internet forum, or message board, is an online discussion site where people can hold conversations in the form of posted messages. Most common topics on forums include questions, comparisons, polls of opinion, as well as debates. By default to be an Internet forum, the web application needs an ability to submit threads and replies. Typically, threads are in newer to older views, and replies in older to newer views. The forum will have a search functionality which can search it's database for previously asked questions. In that way, we won't be needing a separate Q/A,FAQ section for new users. 

The advantage of this over GitHub's issues is that users of the product can easily ask questions which are related to the usages like how to use a particular feature, help in the usages of the product or have discussion threads about the product. It can also be used as a discussion about the product's development cycle and so on. GitHub's issues should tackle bug reports instead of discussion mentioned above. This will help keep the repo issues clean. GitHub has its own [formus](https://github.community/) too. 

I assume that instead of focusing on a variety of things such as communicating over different channels, maintaining a Q/A, a separate FAQ section and seperate section for the important issues. A more centralized system as was indicated by almost every internal community member is required which a forum based system can provide. 
 
* **Proper Documentation**
 
Some platforms such as [this](https://status.hotosm.org/ ) that are used by the tech team to communicate the status of tools. Information regarding feedback collection, forms shared should also be communicated through it. A proper documentation regarding which slack or Github channels are used for feedback collection, and proper guidelines telling the information where to post the respective queries and how to access it should be made available on the community page under a clear section. A small section containing information related to whom and how to contact for a particular type of queries/issues should also be provided there. All community members, especially the new ones should be widely communicated about this document. (Though in my opinion it would great if we can implement a more centralised system such as a forum(maybe integrated with ticket-based system as well) and provide guideline about how to use it rather than dealing with tits and bits of a number of channels and features in the documentation section along with information about whom and how to contact information as mentioned in the last few statements of this section)

* **Updating wiki**

Going through the wiki pages of HOT OSM community, I found that the [working groups page](https://wiki.openstreetmap.org/wiki/Humanitarian_OSM_Team/Working_groups/Technical) had some information regarding when and where meetings are held and it had reports of previous issues solved and minutes of meeting as well stored in google drives with the links provided such as [this](https://drive.google.com/drive/folders/0B9R6_KGwXUFBTU1DY0IyVXhkOEE). But the page seems to be highly outdated. The last report present was from 2017 and other information present was outdated as well. It definitely needs an update at earliest.

###### Advantages:

1) It can solve the issue with finding the previous action reports or minutes of the previous meeting held(if required) which in turn can fasten up the process of dealing with feedback that requires previous reports. As well as being publicly available so that someone can look for it whenever needed.

2) It can be a great place for storing a directory as well(There is a section for members but it doesn’t contain any name on the wiki page), kept up to date of course, where you can find people by catchword. It can solve the common problem of 'who is responsible for what'. Facebook wiki page is doing it quite well as you can see [here](https://wiki.openstreetmap.org/wiki/Facebook_AI-Assisted_Road_Tracing). 
3) All the list of tools mentioned should be accompanied with whom to ask organizational or technical questions. The same applies to many of the campaigns.

###### Disadvantages:

1) This may be too open for some information, for example confidential documentation or few important minutes for meetings. However it is possible to regulate user access.

2) Official wiki will contain the detailed documentation of the product along with answers to the general Q/A faced by the public and some information as mentioned in the last point of the above section  . However, for more detailed questions, users should use the appropriate Q/A forum as wiki should contain only precise information.

3) The flexibility of a wiki’s structure can mean that information becomes disorganised. As a wiki grows, the community plans and administers the structure collaboratively.




* ***Ticket* based systems**
 
A ticket based system can be implemented for tracking the action period which was mentioned by the internal community members as an important issue as they really don’t have an idea about what happens to their feedback once collected and they want to see the actual process being followed and want an escalation policy as well. The general working of such a system can be explained as, you file a ticket, someone from the team is assigned to you, they resolve your ticket while you can monitor the progress of your ticket. Some tools such as [osTicket](http://osTicket.com) can be used which is a widely-used open source support ticket system. It seamlessly integrates inquiries created via email, phone and web-based forms into a simple easy-to-use multi-user web interface. Manage, organize and archive all support requests and responses in one place while providing customers with accountability and responsiveness they deserve.
 
Their advantages include instant assignment of the user's issues and can be assigned to the product's development team which can help resolve the issue quickly. Tickets based systems also have an escalation policy so that they can be escalated to a higher level in case of failure to reach a conclusion. The person assigned to the user's ticket has to give regular updates (let's say every 24 hours) on the ticket. After the ticket is resolved, the user can finally close the ticket. This is quite different from GitHub's issues where there is no possibility to escalate the issue except to ping/CC another person who can potentially resolve it. The system also maintains the history of tickets in the form of reports so the user can look at the previous tickets before creating a new one.

The best thing about this is that we can integrate a ticket based system with a forum. Thereby making it a more concrete centralised system that is required by the members.

* **Issue leveling bots**
 
[Issue Label Bot](https://github.com/apps/issue-label-bot) can be developed that automatically labels issues as either a feature request, bug or question, using machine learning. You can alias these labels so that the labels are personalized for your repo (for example if you prefer enhancement vs. feature_request). This will make the feedback process more specific.
 
 

* **Implement Data-Driven Product Design**


Rather than directly communicating with community members, it is possible to gain insight into their needs via their behavior. In fact, sometimes this is an even better source of data – users may not be fully conscious of how they're using the tool, or may forget to mention a problem. They might not even be aware that they're not seeing or using a potentially useful feature. If users engage a certain feature more often than others, it may be an indication that more features should be built in that area of the product. (Maybe creating buttons to features that don’t actually exist. If enough users click on the buttons, it's taken as a sign that they should actually build the feature can also be a good option.)

* **Related to non-technical feedback**
 
For the regional staff, the collection system must be made more formal and there should be an escalation process. Maybe a software like zendesk(or some open source alternative such as [FreeScout](https://github.com/freescout-helpdesk/freescout) which is the super lightweight free open source help desk and shared inbox) can be a good option to implement. Many low It is designed to help us track, prioritize, and solve support interactions. Or google forms can be circulated that collect autonomous feedback. 







#### Preferences and Satisfaction of Voting Members for their valuable inputs

Voting Members can be considered the “core team”, who are guided by the HOT Membership Code. The Voting Members are people in the HOT community who have shown commitment to the HOT mission. Voting Members are responsible for voting “on matters affecting the Corporation including, but not limited to, the election of directors and new  voting members.” Nominations for membership take place periodically; not a constant rolling program (typically once or twice a year). 

I talked to two of the voting members. Though I noticed that some of the internal community staff are also voting members, three of whom I have actually interviewed for creating this report. So I went for the voting members who aren’t members of the internal community but rather work out of interest and facilitating the system.

##### Satisfaction
* The major reason for them to be associated and keep working with HOT is their consideration that it is a great community to work with and their underlying motivation for the work even if it is without any pay. 

##### Preferences
* I think the main difference between voting members and staff is the obligation to work.
Some of the voting members do not have enough slots available for the work. But staff is not so, staff must work as they are being paid for it. And some of the voting members do not have enough motivation as the time passes maybe because of the repetition of tasks and lack of perks.. In that case, one should step down, but they do not do so in most cases. It might be a high time for the criterions to be redefined.
 
* A communication gap can be clearly seen as voting members were not really informed about how the technical feedback collection works and how it is dealt with afterwards. Though they were informed about channels such hashtag on twitter(#osmjp), [Facebook Groups](https://www.facebook.com/groups/osmjapan/) and  slack [workspace](osm-japan.slack.com). But they weren’t really informed about the frequent feedback being collected. An interest can be clearly seen about giving advice/feedback regarding the tools. I guess it might be due to the lack of time that they aren’t actively participating on channels. It would be a great option to collect their valuable feedback separately through google forms or some other easier channels such as survey monkey.

#### **Recommendations:**
Interested people should be allowed to  self-register as voting members as not everyone capable should have contacts to be “recommended”. There are quite a lot of voting members whom the community never hears from. So it would be a great idea to follow-up with members more closely how they contribute to the organization and pursue them to make contributions. 
